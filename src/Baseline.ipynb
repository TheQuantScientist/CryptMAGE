{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac73b034-5726-4b50-995b-79c0228f3203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 05:11:20.908585: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-14 05:11:22.576474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (12244, 4, 6), dtype: float32\n",
      "y_train shape: (12244,), dtype: float32\n",
      "X_val shape: (3496, 4, 6), dtype: float32\n",
      "y_val shape: (3496,), dtype: float32\n",
      "X_test shape: (1747, 4, 6), dtype: float32\n",
      "y_test shape: (1747,), dtype: float32\n",
      "Epoch 1/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.5274 - loss: 0.6916 - val_accuracy: 0.5995 - val_loss: 0.6687\n",
      "Epoch 2/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5862 - loss: 0.6708 - val_accuracy: 0.5841 - val_loss: 0.6733\n",
      "Epoch 3/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5812 - loss: 0.6699 - val_accuracy: 0.5950 - val_loss: 0.6685\n",
      "Epoch 4/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5793 - loss: 0.6702 - val_accuracy: 0.5721 - val_loss: 0.6751\n",
      "Epoch 5/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5811 - loss: 0.6686 - val_accuracy: 0.6035 - val_loss: 0.6647\n",
      "Epoch 6/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5885 - loss: 0.6608 - val_accuracy: 0.6030 - val_loss: 0.6625\n",
      "Epoch 7/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5938 - loss: 0.6582 - val_accuracy: 0.6138 - val_loss: 0.6566\n",
      "Epoch 8/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6069 - loss: 0.6507 - val_accuracy: 0.6138 - val_loss: 0.6488\n",
      "Epoch 9/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6178 - loss: 0.6437 - val_accuracy: 0.6130 - val_loss: 0.6517\n",
      "Epoch 10/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6204 - loss: 0.6416 - val_accuracy: 0.6279 - val_loss: 0.6402\n",
      "Epoch 11/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6352 - loss: 0.6328 - val_accuracy: 0.6281 - val_loss: 0.6408\n",
      "Epoch 12/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6392 - loss: 0.6243 - val_accuracy: 0.6267 - val_loss: 0.6411\n",
      "Epoch 13/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6318 - loss: 0.6297 - val_accuracy: 0.6393 - val_loss: 0.6355\n",
      "Epoch 14/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6422 - loss: 0.6319 - val_accuracy: 0.6319 - val_loss: 0.6387\n",
      "Epoch 15/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6324 - loss: 0.6276 - val_accuracy: 0.6487 - val_loss: 0.6347\n",
      "Epoch 16/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6373 - loss: 0.6308 - val_accuracy: 0.6239 - val_loss: 0.6380\n",
      "Epoch 17/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6441 - loss: 0.6254 - val_accuracy: 0.6376 - val_loss: 0.6375\n",
      "Epoch 18/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6427 - loss: 0.6286 - val_accuracy: 0.6241 - val_loss: 0.6480\n",
      "Epoch 19/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6411 - loss: 0.6304 - val_accuracy: 0.6304 - val_loss: 0.6351\n",
      "Epoch 20/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6472 - loss: 0.6202 - val_accuracy: 0.6273 - val_loss: 0.6422\n",
      "Epoch 21/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6433 - loss: 0.6260 - val_accuracy: 0.6356 - val_loss: 0.6349\n",
      "Epoch 22/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6398 - loss: 0.6229 - val_accuracy: 0.6324 - val_loss: 0.6435\n",
      "Epoch 23/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6543 - loss: 0.6166 - val_accuracy: 0.6404 - val_loss: 0.6413\n",
      "Epoch 24/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6396 - loss: 0.6208 - val_accuracy: 0.6402 - val_loss: 0.6399\n",
      "Epoch 25/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6432 - loss: 0.6192 - val_accuracy: 0.6390 - val_loss: 0.6344\n",
      "Epoch 26/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6445 - loss: 0.6152 - val_accuracy: 0.6407 - val_loss: 0.6442\n",
      "Epoch 27/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6481 - loss: 0.6176 - val_accuracy: 0.6399 - val_loss: 0.6413\n",
      "Epoch 28/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6477 - loss: 0.6162 - val_accuracy: 0.6433 - val_loss: 0.6404\n",
      "Epoch 29/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6562 - loss: 0.6176 - val_accuracy: 0.6467 - val_loss: 0.6444\n",
      "Epoch 30/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6521 - loss: 0.6124 - val_accuracy: 0.6322 - val_loss: 0.6423\n",
      "Epoch 31/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6502 - loss: 0.6171 - val_accuracy: 0.6419 - val_loss: 0.6418\n",
      "Epoch 32/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6501 - loss: 0.6085 - val_accuracy: 0.6376 - val_loss: 0.6459\n",
      "Epoch 33/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6582 - loss: 0.6030 - val_accuracy: 0.6382 - val_loss: 0.6435\n",
      "Epoch 34/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6583 - loss: 0.6065 - val_accuracy: 0.6287 - val_loss: 0.6559\n",
      "Epoch 35/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6589 - loss: 0.6034 - val_accuracy: 0.6344 - val_loss: 0.6471\n",
      "Epoch 36/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6555 - loss: 0.6024 - val_accuracy: 0.6327 - val_loss: 0.6555\n",
      "Epoch 37/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6579 - loss: 0.6076 - val_accuracy: 0.6362 - val_loss: 0.6542\n",
      "Epoch 38/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6651 - loss: 0.5980 - val_accuracy: 0.6382 - val_loss: 0.6547\n",
      "Epoch 39/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6522 - loss: 0.6042 - val_accuracy: 0.6310 - val_loss: 0.6616\n",
      "Epoch 40/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6643 - loss: 0.5976 - val_accuracy: 0.6419 - val_loss: 0.6624\n",
      "Epoch 41/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6635 - loss: 0.5940 - val_accuracy: 0.6287 - val_loss: 0.6664\n",
      "Epoch 42/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6620 - loss: 0.5901 - val_accuracy: 0.6384 - val_loss: 0.6605\n",
      "Epoch 43/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6727 - loss: 0.5879 - val_accuracy: 0.6413 - val_loss: 0.6545\n",
      "Epoch 44/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6604 - loss: 0.5902 - val_accuracy: 0.6307 - val_loss: 0.6675\n",
      "Epoch 45/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6755 - loss: 0.5839 - val_accuracy: 0.6382 - val_loss: 0.6658\n",
      "Epoch 46/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6693 - loss: 0.5853 - val_accuracy: 0.6336 - val_loss: 0.6657\n",
      "Epoch 47/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6734 - loss: 0.5813 - val_accuracy: 0.6313 - val_loss: 0.6716\n",
      "Epoch 48/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6725 - loss: 0.5819 - val_accuracy: 0.6344 - val_loss: 0.6672\n",
      "Epoch 49/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6738 - loss: 0.5784 - val_accuracy: 0.6382 - val_loss: 0.6779\n",
      "Epoch 50/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6837 - loss: 0.5745 - val_accuracy: 0.6253 - val_loss: 0.6895\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Training-Validation Metrics:\n",
      "AUROC: 0.6831485101719391\n",
      "AUPRC: 0.6192192468646849\n",
      "Accuracy: 0.6845802025481869\n",
      "Precision: 0.6987227648384673\n",
      "Recall: 0.622281699565072\n",
      "F1 Score: 0.6582905680410547\n",
      "\n",
      "Validation Metrics:\n",
      "AUROC: 0.6226309054295625\n",
      "AUPRC: 0.5616552484206521\n",
      "Accuracy: 0.6252860411899314\n",
      "Precision: 0.6271186440677966\n",
      "Recall: 0.5489614243323442\n",
      "F1 Score: 0.5854430379746834\n",
      "\n",
      "Test Metrics:\n",
      "AUROC: 0.592046399718726\n",
      "AUPRC: 0.5367880245943388\n",
      "Accuracy: 0.5867200915855753\n",
      "Precision: 0.5532646048109966\n",
      "Recall: 0.7612293144208038\n",
      "F1 Score: 0.6407960199004975\n"
     ]
    }
   ],
   "source": [
    "# GRU MODELS  \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "\n",
    "# Load the time series data\n",
    "data = pd.read_csv('NMC.csv')\n",
    "\n",
    "# Ensure the data has the necessary columns: 'Open', 'High', 'Close', 'Volume', 'RSI', 'MA'\n",
    "assert set(['Open', 'High', 'Close', 'Volume', 'RSI', 'MA']).issubset(data.columns), \"Missing necessary columns in the data\"\n",
    "\n",
    "# Step 1: Labeling the data\n",
    "def label_data(df, interval=4):\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - interval + 1):\n",
    "        if df['Open'][i] < df['Close'][i + interval - 1]:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    labels.extend([np.nan] * (interval - 1))\n",
    "    return labels\n",
    "\n",
    "data['Label'] = label_data(data)\n",
    "\n",
    "# Drop rows with NaN labels\n",
    "data = data.dropna(subset=['Label'])\n",
    "\n",
    "# Step 2: Splitting the data\n",
    "train_size = int(len(data) * 0.7)\n",
    "val_size = int(len(data) * 0.2)\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "train_data = data.iloc[:train_size]\n",
    "val_data = data.iloc[train_size:train_size + val_size]\n",
    "test_data = data.iloc[train_size + val_size:]\n",
    "\n",
    "# Step 3: Normalizing the data (without data leakage)\n",
    "scaler = StandardScaler()\n",
    "features = ['Open', 'High', 'Close', 'Volume', 'RSI', 'MA']\n",
    "\n",
    "train_data.loc[:, features] = scaler.fit_transform(train_data[features])\n",
    "val_data.loc[:, features] = scaler.transform(val_data[features])\n",
    "test_data.loc[:, features] = scaler.transform(test_data[features])\n",
    "\n",
    "# Ensure there are no NaN values\n",
    "assert not train_data[features].isnull().values.any(), \"Train data contains NaN values\"\n",
    "assert not val_data[features].isnull().values.any(), \"Validation data contains NaN values\"\n",
    "assert not test_data[features].isnull().values.any(), \"Test data contains NaN values\"\n",
    "\n",
    "# Step 4: Creating sequences\n",
    "def create_sequences(data, time_steps=4):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps + 1):\n",
    "        X.append(data.iloc[i:(i + time_steps), :].drop(columns=['Datetime', 'Label']).values)\n",
    "        y.append(data.iloc[i + time_steps - 1]['Label'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_sequences(train_data)\n",
    "X_val, y_val = create_sequences(val_data)\n",
    "X_test, y_test = create_sequences(test_data)\n",
    "\n",
    "# Ensure all data is of type float\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# Check the shapes and types of the data\n",
    "print(f\"X_train shape: {X_train.shape}, dtype: {X_train.dtype}\")\n",
    "print(f\"y_train shape: {y_train.shape}, dtype: {y_train.dtype}\")\n",
    "print(f\"X_val shape: {X_val.shape}, dtype: {X_val.dtype}\")\n",
    "print(f\"y_val shape: {y_val.shape}, dtype: {y_val.dtype}\")\n",
    "print(f\"X_test shape: {X_test.shape}, dtype: {X_test.dtype}\")\n",
    "print(f\"y_test shape: {y_test.shape}, dtype: {y_test.dtype}\")\n",
    "\n",
    "# Step 5: Building the GRU model\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    GRU(128, return_sequences=True),\n",
    "    GRU(128),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Training the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Step 7: Evaluating the model\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X).round()\n",
    "    auroc = roc_auc_score(y, y_pred)\n",
    "    auprc = average_precision_score(y, y_pred)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return auroc, auprc, accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluation on training-validation set\n",
    "train_val_auroc, train_val_auprc, train_val_accuracy, train_val_precision, train_val_recall, train_val_f1 = evaluate_model(model, X_train, y_train)\n",
    "val_auroc, val_auprc, val_accuracy, val_precision, val_recall, val_f1 = evaluate_model(model, X_val, y_val)\n",
    "\n",
    "# Evaluation on test set\n",
    "test_auroc, test_auprc, test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "print(\"Training-Validation Metrics:\")\n",
    "print(f\"AUROC: {train_val_auroc}\")\n",
    "print(f\"AUPRC: {train_val_auprc}\")\n",
    "print(f\"Accuracy: {train_val_accuracy}\")\n",
    "print(f\"Precision: {train_val_precision}\")\n",
    "print(f\"Recall: {train_val_recall}\")\n",
    "print(f\"F1 Score: {train_val_f1}\")\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"AUROC: {val_auroc}\")\n",
    "print(f\"AUPRC: {val_auprc}\")\n",
    "print(f\"Accuracy: {val_accuracy}\")\n",
    "print(f\"Precision: {val_precision}\")\n",
    "print(f\"Recall: {val_recall}\")\n",
    "print(f\"F1 Score: {val_f1}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"AUROC: {test_auroc}\")\n",
    "print(f\"AUPRC: {test_auprc}\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"Precision: {test_precision}\")\n",
    "print(f\"Recall: {test_recall}\")\n",
    "print(f\"F1 Score: {test_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e54b9d-7f3d-43e0-adca-8abc094c339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (12244, 4, 6), dtype: float32\n",
      "y_train shape: (12244,), dtype: float32\n",
      "X_val shape: (3496, 4, 6), dtype: float32\n",
      "y_val shape: (3496,), dtype: float32\n",
      "X_test shape: (1747, 4, 6), dtype: float32\n",
      "y_test shape: (1747,), dtype: float32\n",
      "Epoch 1/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5289 - loss: 0.6922 - val_accuracy: 0.5429 - val_loss: 0.6872\n",
      "Epoch 2/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5662 - loss: 0.6796 - val_accuracy: 0.5901 - val_loss: 0.6705\n",
      "Epoch 3/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5755 - loss: 0.6721 - val_accuracy: 0.5941 - val_loss: 0.6676\n",
      "Epoch 4/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5854 - loss: 0.6688 - val_accuracy: 0.5932 - val_loss: 0.6694\n",
      "Epoch 5/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5818 - loss: 0.6707 - val_accuracy: 0.5890 - val_loss: 0.6686\n",
      "Epoch 6/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5907 - loss: 0.6643 - val_accuracy: 0.5941 - val_loss: 0.6667\n",
      "Epoch 7/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5842 - loss: 0.6634 - val_accuracy: 0.5978 - val_loss: 0.6670\n",
      "Epoch 8/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5935 - loss: 0.6638 - val_accuracy: 0.6027 - val_loss: 0.6644\n",
      "Epoch 9/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5951 - loss: 0.6617 - val_accuracy: 0.6013 - val_loss: 0.6670\n",
      "Epoch 10/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5977 - loss: 0.6556 - val_accuracy: 0.5910 - val_loss: 0.6685\n",
      "Epoch 11/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6058 - loss: 0.6530 - val_accuracy: 0.5987 - val_loss: 0.6637\n",
      "Epoch 12/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6038 - loss: 0.6537 - val_accuracy: 0.6101 - val_loss: 0.6620\n",
      "Epoch 13/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6127 - loss: 0.6470 - val_accuracy: 0.6239 - val_loss: 0.6525\n",
      "Epoch 14/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6191 - loss: 0.6424 - val_accuracy: 0.6356 - val_loss: 0.6540\n",
      "Epoch 15/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6296 - loss: 0.6365 - val_accuracy: 0.6227 - val_loss: 0.6433\n",
      "Epoch 16/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6384 - loss: 0.6374 - val_accuracy: 0.6390 - val_loss: 0.6427\n",
      "Epoch 17/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6340 - loss: 0.6296 - val_accuracy: 0.6241 - val_loss: 0.6446\n",
      "Epoch 18/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6258 - loss: 0.6354 - val_accuracy: 0.6170 - val_loss: 0.6515\n",
      "Epoch 19/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6337 - loss: 0.6289 - val_accuracy: 0.6290 - val_loss: 0.6390\n",
      "Epoch 20/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6436 - loss: 0.6227 - val_accuracy: 0.6370 - val_loss: 0.6403\n",
      "Epoch 21/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6355 - loss: 0.6271 - val_accuracy: 0.6387 - val_loss: 0.6348\n",
      "Epoch 22/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6434 - loss: 0.6221 - val_accuracy: 0.6410 - val_loss: 0.6357\n",
      "Epoch 23/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6440 - loss: 0.6210 - val_accuracy: 0.6450 - val_loss: 0.6390\n",
      "Epoch 24/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6440 - loss: 0.6236 - val_accuracy: 0.6216 - val_loss: 0.6452\n",
      "Epoch 25/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6279 - loss: 0.6279 - val_accuracy: 0.6339 - val_loss: 0.6360\n",
      "Epoch 26/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6455 - loss: 0.6227 - val_accuracy: 0.6313 - val_loss: 0.6439\n",
      "Epoch 27/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6344 - loss: 0.6263 - val_accuracy: 0.6324 - val_loss: 0.6390\n",
      "Epoch 28/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6428 - loss: 0.6220 - val_accuracy: 0.6419 - val_loss: 0.6364\n",
      "Epoch 29/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6474 - loss: 0.6205 - val_accuracy: 0.6310 - val_loss: 0.6380\n",
      "Epoch 30/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6445 - loss: 0.6136 - val_accuracy: 0.6387 - val_loss: 0.6396\n",
      "Epoch 31/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6403 - loss: 0.6203 - val_accuracy: 0.6387 - val_loss: 0.6368\n",
      "Epoch 32/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6414 - loss: 0.6218 - val_accuracy: 0.6259 - val_loss: 0.6483\n",
      "Epoch 33/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6419 - loss: 0.6171 - val_accuracy: 0.6347 - val_loss: 0.6422\n",
      "Epoch 34/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6435 - loss: 0.6154 - val_accuracy: 0.6247 - val_loss: 0.6455\n",
      "Epoch 35/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6494 - loss: 0.6158 - val_accuracy: 0.6416 - val_loss: 0.6402\n",
      "Epoch 36/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6518 - loss: 0.6151 - val_accuracy: 0.6276 - val_loss: 0.6487\n",
      "Epoch 37/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6453 - loss: 0.6148 - val_accuracy: 0.6330 - val_loss: 0.6471\n",
      "Epoch 38/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6554 - loss: 0.6082 - val_accuracy: 0.6324 - val_loss: 0.6465\n",
      "Epoch 39/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6536 - loss: 0.6082 - val_accuracy: 0.6256 - val_loss: 0.6644\n",
      "Epoch 40/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6502 - loss: 0.6134 - val_accuracy: 0.6390 - val_loss: 0.6508\n",
      "Epoch 41/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6485 - loss: 0.6081 - val_accuracy: 0.6313 - val_loss: 0.6582\n",
      "Epoch 42/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6574 - loss: 0.6046 - val_accuracy: 0.6382 - val_loss: 0.6569\n",
      "Epoch 43/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6593 - loss: 0.6025 - val_accuracy: 0.6362 - val_loss: 0.6542\n",
      "Epoch 44/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6560 - loss: 0.6065 - val_accuracy: 0.6399 - val_loss: 0.6633\n",
      "Epoch 45/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6657 - loss: 0.5984 - val_accuracy: 0.6299 - val_loss: 0.6568\n",
      "Epoch 46/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6625 - loss: 0.6030 - val_accuracy: 0.6393 - val_loss: 0.6613\n",
      "Epoch 47/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6670 - loss: 0.5979 - val_accuracy: 0.6436 - val_loss: 0.6678\n",
      "Epoch 48/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6591 - loss: 0.6005 - val_accuracy: 0.6399 - val_loss: 0.6688\n",
      "Epoch 49/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6656 - loss: 0.5947 - val_accuracy: 0.6304 - val_loss: 0.6673\n",
      "Epoch 50/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6575 - loss: 0.5975 - val_accuracy: 0.6402 - val_loss: 0.6921\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Training-Validation Metrics:\n",
      "AUROC: 0.6684073916307876\n",
      "AUPRC: 0.6040843840137753\n",
      "Accuracy: 0.6693074158771644\n",
      "Precision: 0.672078501338091\n",
      "Recall: 0.6301438608230178\n",
      "F1 Score: 0.6504359837693172\n",
      "\n",
      "Validation Metrics:\n",
      "AUROC: 0.6389489224275652\n",
      "AUPRC: 0.5730122277684626\n",
      "Accuracy: 0.6401601830663616\n",
      "Precision: 0.6323620582765034\n",
      "Recall: 0.6053412462908012\n",
      "F1 Score: 0.6185567010309279\n",
      "\n",
      "Test Metrics:\n",
      "AUROC: 0.584402541961519\n",
      "AUPRC: 0.5313054988236768\n",
      "Accuracy: 0.5764167143674871\n",
      "Precision: 0.5403963414634146\n",
      "Recall: 0.8380614657210402\n",
      "F1 Score: 0.6570898980537535\n"
     ]
    }
   ],
   "source": [
    "# LSTM \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load the time series data\n",
    "data = pd.read_csv('NMC.csv')\n",
    "\n",
    "# Ensure the data has the necessary columns: 'Open', 'High', 'Close', 'Volume', 'RSI', 'MA'\n",
    "assert set(['Open', 'High', 'Close', 'Volume', 'RSI', 'MA']).issubset(data.columns), \"Missing necessary columns in the data\"\n",
    "\n",
    "# Step 1: Labeling the data\n",
    "def label_data(df, interval=4):\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - interval + 1):\n",
    "        if df['Open'][i] < df['Close'][i + interval - 1]:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    labels.extend([np.nan] * (interval - 1))\n",
    "    return labels\n",
    "\n",
    "data['Label'] = label_data(data)\n",
    "\n",
    "# Drop rows with NaN labels\n",
    "data = data.dropna(subset=['Label'])\n",
    "\n",
    "# Step 2: Splitting the data\n",
    "train_size = int(len(data) * 0.7)\n",
    "val_size = int(len(data) * 0.2)\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "train_data = data.iloc[:train_size]\n",
    "val_data = data.iloc[train_size:train_size + val_size]\n",
    "test_data = data.iloc[train_size + val_size:]\n",
    "\n",
    "# Step 3: Normalizing the data (without data leakage)\n",
    "scaler = StandardScaler()\n",
    "features = ['Open', 'High', 'Close', 'Volume', 'RSI', 'MA']\n",
    "\n",
    "train_data.loc[:, features] = scaler.fit_transform(train_data[features])\n",
    "val_data.loc[:, features] = scaler.transform(val_data[features])\n",
    "test_data.loc[:, features] = scaler.transform(test_data[features])\n",
    "\n",
    "# Ensure there are no NaN values\n",
    "assert not train_data[features].isnull().values.any(), \"Train data contains NaN values\"\n",
    "assert not val_data[features].isnull().values.any(), \"Validation data contains NaN values\"\n",
    "assert not test_data[features].isnull().values.any(), \"Test data contains NaN values\"\n",
    "\n",
    "# Step 4: Creating sequences\n",
    "def create_sequences(data, time_steps=4):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps + 1):\n",
    "        X.append(data.iloc[i:(i + time_steps), :].drop(columns=['Datetime', 'Label']).values)\n",
    "        y.append(data.iloc[i + time_steps - 1]['Label'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_sequences(train_data)\n",
    "X_val, y_val = create_sequences(val_data)\n",
    "X_test, y_test = create_sequences(test_data)\n",
    "\n",
    "# Ensure all data is of type float\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# Check the shapes and types of the data\n",
    "print(f\"X_train shape: {X_train.shape}, dtype: {X_train.dtype}\")\n",
    "print(f\"y_train shape: {y_train.shape}, dtype: {y_train.dtype}\")\n",
    "print(f\"X_val shape: {X_val.shape}, dtype: {X_val.dtype}\")\n",
    "print(f\"y_val shape: {y_val.shape}, dtype: {y_val.dtype}\")\n",
    "print(f\"X_test shape: {X_test.shape}, dtype: {X_test.dtype}\")\n",
    "print(f\"y_test shape: {y_test.shape}, dtype: {y_test.dtype}\")\n",
    "\n",
    "# Step 5: Building the LSTM model\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(128),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Training the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Step 7: Evaluating the model\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X).round()\n",
    "    auroc = roc_auc_score(y, y_pred)\n",
    "    auprc = average_precision_score(y, y_pred)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return auroc, auprc, accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluation on training-validation set\n",
    "train_val_auroc, train_val_auprc, train_val_accuracy, train_val_precision, train_val_recall, train_val_f1 = evaluate_model(model, X_train, y_train)\n",
    "val_auroc, val_auprc, val_accuracy, val_precision, val_recall, val_f1 = evaluate_model(model, X_val, y_val)\n",
    "\n",
    "# Evaluation on test set\n",
    "test_auroc, test_auprc, test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "print(\"Training-Validation Metrics:\")\n",
    "print(f\"AUROC: {train_val_auroc}\")\n",
    "print(f\"AUPRC: {train_val_auprc}\")\n",
    "print(f\"Accuracy: {train_val_accuracy}\")\n",
    "print(f\"Precision: {train_val_precision}\")\n",
    "print(f\"Recall: {train_val_recall}\")\n",
    "print(f\"F1 Score: {train_val_f1}\")\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"AUROC: {val_auroc}\")\n",
    "print(f\"AUPRC: {val_auprc}\")\n",
    "print(f\"Accuracy: {val_accuracy}\")\n",
    "print(f\"Precision: {val_precision}\")\n",
    "print(f\"Recall: {val_recall}\")\n",
    "print(f\"F1 Score: {val_f1}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"AUROC: {test_auroc}\")\n",
    "print(f\"AUPRC: {test_auprc}\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"Precision: {test_precision}\")\n",
    "print(f\"Recall: {test_recall}\")\n",
    "print(f\"F1 Score: {test_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03257dfb-cf8e-4b7a-9116-93ea09ddf46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (12244, 4, 6), dtype: float32\n",
      "y_train shape: (12244,), dtype: float32\n",
      "X_val shape: (3496, 4, 6), dtype: float32\n",
      "y_val shape: (3496,), dtype: float32\n",
      "X_test shape: (1747, 4, 6), dtype: float32\n",
      "y_test shape: (1747,), dtype: float32\n",
      "Epoch 1/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5231 - loss: 0.6944 - val_accuracy: 0.5478 - val_loss: 0.6916\n",
      "Epoch 2/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5431 - loss: 0.6859 - val_accuracy: 0.5475 - val_loss: 0.6845\n",
      "Epoch 3/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5496 - loss: 0.6857 - val_accuracy: 0.5638 - val_loss: 0.6821\n",
      "Epoch 4/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5587 - loss: 0.6801 - val_accuracy: 0.5535 - val_loss: 0.6833\n",
      "Epoch 5/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5569 - loss: 0.6796 - val_accuracy: 0.5589 - val_loss: 0.6789\n",
      "Epoch 6/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5619 - loss: 0.6812 - val_accuracy: 0.5549 - val_loss: 0.6864\n",
      "Epoch 7/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5676 - loss: 0.6747 - val_accuracy: 0.5724 - val_loss: 0.6769\n",
      "Epoch 8/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5745 - loss: 0.6760 - val_accuracy: 0.5695 - val_loss: 0.6763\n",
      "Epoch 9/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5756 - loss: 0.6742 - val_accuracy: 0.5652 - val_loss: 0.6750\n",
      "Epoch 10/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5745 - loss: 0.6712 - val_accuracy: 0.5755 - val_loss: 0.6733\n",
      "Epoch 11/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5658 - loss: 0.6733 - val_accuracy: 0.5624 - val_loss: 0.6753\n",
      "Epoch 12/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5787 - loss: 0.6691 - val_accuracy: 0.5649 - val_loss: 0.6755\n",
      "Epoch 13/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5704 - loss: 0.6744 - val_accuracy: 0.5709 - val_loss: 0.6788\n",
      "Epoch 14/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5807 - loss: 0.6667 - val_accuracy: 0.5666 - val_loss: 0.6758\n",
      "Epoch 15/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5842 - loss: 0.6681 - val_accuracy: 0.5695 - val_loss: 0.6796\n",
      "Epoch 16/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5760 - loss: 0.6705 - val_accuracy: 0.5769 - val_loss: 0.6727\n",
      "Epoch 17/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5830 - loss: 0.6657 - val_accuracy: 0.5752 - val_loss: 0.6731\n",
      "Epoch 18/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5882 - loss: 0.6639 - val_accuracy: 0.5818 - val_loss: 0.6735\n",
      "Epoch 19/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5841 - loss: 0.6635 - val_accuracy: 0.5812 - val_loss: 0.6734\n",
      "Epoch 20/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5843 - loss: 0.6631 - val_accuracy: 0.5598 - val_loss: 0.6792\n",
      "Epoch 21/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5848 - loss: 0.6638 - val_accuracy: 0.5841 - val_loss: 0.6718\n",
      "Epoch 22/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5925 - loss: 0.6641 - val_accuracy: 0.5890 - val_loss: 0.6723\n",
      "Epoch 23/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5893 - loss: 0.6615 - val_accuracy: 0.5830 - val_loss: 0.6726\n",
      "Epoch 24/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5860 - loss: 0.6629 - val_accuracy: 0.5841 - val_loss: 0.6693\n",
      "Epoch 25/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5911 - loss: 0.6597 - val_accuracy: 0.5718 - val_loss: 0.6776\n",
      "Epoch 26/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5841 - loss: 0.6631 - val_accuracy: 0.5844 - val_loss: 0.6751\n",
      "Epoch 27/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5843 - loss: 0.6590 - val_accuracy: 0.5827 - val_loss: 0.6719\n",
      "Epoch 28/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5935 - loss: 0.6576 - val_accuracy: 0.5744 - val_loss: 0.6728\n",
      "Epoch 29/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5867 - loss: 0.6607 - val_accuracy: 0.5741 - val_loss: 0.6751\n",
      "Epoch 30/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5929 - loss: 0.6569 - val_accuracy: 0.5764 - val_loss: 0.6707\n",
      "Epoch 31/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5897 - loss: 0.6583 - val_accuracy: 0.5727 - val_loss: 0.6746\n",
      "Epoch 32/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5987 - loss: 0.6574 - val_accuracy: 0.5689 - val_loss: 0.6816\n",
      "Epoch 33/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6005 - loss: 0.6528 - val_accuracy: 0.5747 - val_loss: 0.6733\n",
      "Epoch 34/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5951 - loss: 0.6575 - val_accuracy: 0.5781 - val_loss: 0.6740\n",
      "Epoch 35/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6034 - loss: 0.6523 - val_accuracy: 0.5769 - val_loss: 0.6774\n",
      "Epoch 36/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6065 - loss: 0.6536 - val_accuracy: 0.5755 - val_loss: 0.6791\n",
      "Epoch 37/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5954 - loss: 0.6570 - val_accuracy: 0.5727 - val_loss: 0.6829\n",
      "Epoch 38/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6048 - loss: 0.6518 - val_accuracy: 0.5747 - val_loss: 0.6788\n",
      "Epoch 39/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6022 - loss: 0.6519 - val_accuracy: 0.5784 - val_loss: 0.6775\n",
      "Epoch 40/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5965 - loss: 0.6531 - val_accuracy: 0.5781 - val_loss: 0.6766\n",
      "Epoch 41/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6015 - loss: 0.6516 - val_accuracy: 0.5727 - val_loss: 0.6811\n",
      "Epoch 42/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6032 - loss: 0.6487 - val_accuracy: 0.5752 - val_loss: 0.6834\n",
      "Epoch 43/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6017 - loss: 0.6481 - val_accuracy: 0.5815 - val_loss: 0.6810\n",
      "Epoch 44/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6072 - loss: 0.6448 - val_accuracy: 0.5729 - val_loss: 0.6881\n",
      "Epoch 45/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6036 - loss: 0.6439 - val_accuracy: 0.5684 - val_loss: 0.6810\n",
      "Epoch 46/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6035 - loss: 0.6468 - val_accuracy: 0.5861 - val_loss: 0.6798\n",
      "Epoch 47/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6144 - loss: 0.6415 - val_accuracy: 0.5721 - val_loss: 0.6846\n",
      "Epoch 48/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6091 - loss: 0.6420 - val_accuracy: 0.5709 - val_loss: 0.6865\n",
      "Epoch 49/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6131 - loss: 0.6421 - val_accuracy: 0.5727 - val_loss: 0.6849\n",
      "Epoch 50/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6073 - loss: 0.6456 - val_accuracy: 0.5675 - val_loss: 0.6872\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step\n",
      "Training-Validation Metrics:\n",
      "AUROC: 0.6144020254284862\n",
      "AUPRC: 0.562627605227212\n",
      "Accuracy: 0.6169552433845149\n",
      "Precision: 0.6352941176470588\n",
      "Recall: 0.5058548009367682\n",
      "F1 Score: 0.5632333767926988\n",
      "\n",
      "Validation Metrics:\n",
      "AUROC: 0.5622360549690566\n",
      "AUPRC: 0.5187571598180425\n",
      "Accuracy: 0.5675057208237986\n",
      "Precision: 0.5703824247355573\n",
      "Recall: 0.41602373887240357\n",
      "F1 Score: 0.48112560054907344\n",
      "\n",
      "Test Metrics:\n",
      "AUROC: 0.5792244236112751\n",
      "AUPRC: 0.5287357851132167\n",
      "Accuracy: 0.5741270749856897\n",
      "Precision: 0.5442708333333334\n",
      "Recall: 0.7411347517730497\n",
      "F1 Score: 0.6276276276276276\n"
     ]
    }
   ],
   "source": [
    "# CNN MODEL \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "# Load the time series data\n",
    "data = pd.read_csv('NMC.csv')\n",
    "\n",
    "# Ensure the data has the necessary columns: 'Open', 'High', 'Close', 'Volume', 'RSI', 'MA'\n",
    "assert set(['Open', 'High', 'Close', 'Volume', 'RSI', 'MA']).issubset(data.columns), \"Missing necessary columns in the data\"\n",
    "\n",
    "# Step 1: Labeling the data\n",
    "def label_data(df, interval=4):\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - interval + 1):\n",
    "        if df['Open'][i] < df['Close'][i + interval - 1]:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    labels.extend([np.nan] * (interval - 1))\n",
    "    return labels\n",
    "\n",
    "data['Label'] = label_data(data)\n",
    "\n",
    "# Drop rows with NaN labels\n",
    "data = data.dropna(subset=['Label'])\n",
    "\n",
    "# Step 2: Splitting the data\n",
    "train_size = int(len(data) * 0.7)\n",
    "val_size = int(len(data) * 0.2)\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "train_data = data.iloc[:train_size]\n",
    "val_data = data.iloc[train_size:train_size + val_size]\n",
    "test_data = data.iloc[train_size + val_size:]\n",
    "\n",
    "# Step 3: Normalizing the data (without data leakage)\n",
    "scaler = StandardScaler()\n",
    "features = ['Open', 'High', 'Close', 'Volume', 'RSI', 'MA']\n",
    "\n",
    "train_data.loc[:, features] = scaler.fit_transform(train_data[features])\n",
    "val_data.loc[:, features] = scaler.transform(val_data[features])\n",
    "test_data.loc[:, features] = scaler.transform(test_data[features])\n",
    "\n",
    "# Ensure there are no NaN values\n",
    "assert not train_data[features].isnull().values.any(), \"Train data contains NaN values\"\n",
    "assert not val_data[features].isnull().values.any(), \"Validation data contains NaN values\"\n",
    "assert not test_data[features].isnull().values.any(), \"Test data contains NaN values\"\n",
    "\n",
    "# Step 4: Creating sequences\n",
    "def create_sequences(data, time_steps=4):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps + 1):\n",
    "        X.append(data.iloc[i:(i + time_steps), :].drop(columns=['Datetime', 'Label']).values)\n",
    "        y.append(data.iloc[i + time_steps - 1]['Label'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_sequences(train_data)\n",
    "X_val, y_val = create_sequences(val_data)\n",
    "X_test, y_test = create_sequences(test_data)\n",
    "\n",
    "# Ensure all data is of type float\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# Check the shapes and types of the data\n",
    "print(f\"X_train shape: {X_train.shape}, dtype: {X_train.dtype}\")\n",
    "print(f\"y_train shape: {y_train.shape}, dtype: {y_train.dtype}\")\n",
    "print(f\"X_val shape: {X_val.shape}, dtype: {X_val.dtype}\")\n",
    "print(f\"y_val shape: {y_val.shape}, dtype: {y_val.dtype}\")\n",
    "print(f\"X_test shape: {X_test.shape}, dtype: {X_test.dtype}\")\n",
    "print(f\"y_test shape: {y_test.shape}, dtype: {y_test.dtype}\")\n",
    "\n",
    "# Step 5: Building the CNN model\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Training the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Step 7: Evaluating the model\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X).round()\n",
    "    auroc = roc_auc_score(y, y_pred)\n",
    "    auprc = average_precision_score(y, y_pred)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return auroc, auprc, accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluation on training-validation set\n",
    "train_val_auroc, train_val_auprc, train_val_accuracy, train_val_precision, train_val_recall, train_val_f1 = evaluate_model(model, X_train, y_train)\n",
    "val_auroc, val_auprc, val_accuracy, val_precision, val_recall, val_f1 = evaluate_model(model, X_val, y_val)\n",
    "\n",
    "# Evaluation on test set\n",
    "test_auroc, test_auprc, test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "print(\"Training-Validation Metrics:\")\n",
    "print(f\"AUROC: {train_val_auroc}\")\n",
    "print(f\"AUPRC: {train_val_auprc}\")\n",
    "print(f\"Accuracy: {train_val_accuracy}\")\n",
    "print(f\"Precision: {train_val_precision}\")\n",
    "print(f\"Recall: {train_val_recall}\")\n",
    "print(f\"F1 Score: {train_val_f1}\")\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"AUROC: {val_auroc}\")\n",
    "print(f\"AUPRC: {val_auprc}\")\n",
    "print(f\"Accuracy: {val_accuracy}\")\n",
    "print(f\"Precision: {val_precision}\")\n",
    "print(f\"Recall: {val_recall}\")\n",
    "print(f\"F1 Score: {val_f1}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"AUROC: {test_auroc}\")\n",
    "print(f\"AUPRC: {test_auprc}\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"Precision: {test_precision}\")\n",
    "print(f\"Recall: {test_recall}\")\n",
    "print(f\"F1 Score: {test_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d755b134-e027-4f89-863c-1a676238764a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (12244, 4, 6), dtype: float32\n",
      "y_train shape: (12244,), dtype: float32\n",
      "X_val shape: (3496, 4, 6), dtype: float32\n",
      "y_val shape: (3496,), dtype: float32\n",
      "X_test shape: (1747, 4, 6), dtype: float32\n",
      "y_test shape: (1747,), dtype: float32\n",
      "Epoch 1/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5290 - loss: 0.6920 - val_accuracy: 0.5463 - val_loss: 0.6884\n",
      "Epoch 2/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5431 - loss: 0.6874 - val_accuracy: 0.5575 - val_loss: 0.6829\n",
      "Epoch 3/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5502 - loss: 0.6828 - val_accuracy: 0.5566 - val_loss: 0.6814\n",
      "Epoch 4/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5493 - loss: 0.6814 - val_accuracy: 0.5592 - val_loss: 0.6808\n",
      "Epoch 5/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5687 - loss: 0.6781 - val_accuracy: 0.5586 - val_loss: 0.6802\n",
      "Epoch 6/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5596 - loss: 0.6776 - val_accuracy: 0.5646 - val_loss: 0.6790\n",
      "Epoch 7/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5660 - loss: 0.6752 - val_accuracy: 0.5584 - val_loss: 0.6767\n",
      "Epoch 8/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5680 - loss: 0.6731 - val_accuracy: 0.5641 - val_loss: 0.6751\n",
      "Epoch 9/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5703 - loss: 0.6744 - val_accuracy: 0.5698 - val_loss: 0.6772\n",
      "Epoch 10/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5699 - loss: 0.6743 - val_accuracy: 0.5621 - val_loss: 0.6759\n",
      "Epoch 11/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5818 - loss: 0.6700 - val_accuracy: 0.5604 - val_loss: 0.6798\n",
      "Epoch 12/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5770 - loss: 0.6673 - val_accuracy: 0.5732 - val_loss: 0.6760\n",
      "Epoch 13/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5823 - loss: 0.6688 - val_accuracy: 0.5707 - val_loss: 0.6749\n",
      "Epoch 14/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5768 - loss: 0.6664 - val_accuracy: 0.5675 - val_loss: 0.6739\n",
      "Epoch 15/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5774 - loss: 0.6672 - val_accuracy: 0.5749 - val_loss: 0.6737\n",
      "Epoch 16/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5839 - loss: 0.6651 - val_accuracy: 0.5689 - val_loss: 0.6759\n",
      "Epoch 17/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5833 - loss: 0.6652 - val_accuracy: 0.5741 - val_loss: 0.6764\n",
      "Epoch 18/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5805 - loss: 0.6663 - val_accuracy: 0.5761 - val_loss: 0.6738\n",
      "Epoch 19/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5874 - loss: 0.6668 - val_accuracy: 0.5758 - val_loss: 0.6746\n",
      "Epoch 20/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5787 - loss: 0.6653 - val_accuracy: 0.5784 - val_loss: 0.6721\n",
      "Epoch 21/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5874 - loss: 0.6634 - val_accuracy: 0.5804 - val_loss: 0.6750\n",
      "Epoch 22/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5811 - loss: 0.6610 - val_accuracy: 0.5801 - val_loss: 0.6757\n",
      "Epoch 23/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5738 - loss: 0.6649 - val_accuracy: 0.5695 - val_loss: 0.6794\n",
      "Epoch 24/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5870 - loss: 0.6603 - val_accuracy: 0.5632 - val_loss: 0.6824\n",
      "Epoch 25/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5789 - loss: 0.6639 - val_accuracy: 0.5795 - val_loss: 0.6740\n",
      "Epoch 26/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5847 - loss: 0.6607 - val_accuracy: 0.5890 - val_loss: 0.6737\n",
      "Epoch 27/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5879 - loss: 0.6586 - val_accuracy: 0.5832 - val_loss: 0.6773\n",
      "Epoch 28/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5918 - loss: 0.6555 - val_accuracy: 0.5721 - val_loss: 0.6776\n",
      "Epoch 29/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5871 - loss: 0.6582 - val_accuracy: 0.5781 - val_loss: 0.6764\n",
      "Epoch 30/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6043 - loss: 0.6504 - val_accuracy: 0.5721 - val_loss: 0.6796\n",
      "Epoch 31/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5988 - loss: 0.6542 - val_accuracy: 0.5830 - val_loss: 0.6781\n",
      "Epoch 32/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5967 - loss: 0.6552 - val_accuracy: 0.5767 - val_loss: 0.6794\n",
      "Epoch 33/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5849 - loss: 0.6585 - val_accuracy: 0.5852 - val_loss: 0.6830\n",
      "Epoch 34/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6028 - loss: 0.6520 - val_accuracy: 0.5747 - val_loss: 0.6823\n",
      "Epoch 35/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5980 - loss: 0.6503 - val_accuracy: 0.5689 - val_loss: 0.6816\n",
      "Epoch 36/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5995 - loss: 0.6477 - val_accuracy: 0.5815 - val_loss: 0.6800\n",
      "Epoch 37/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5964 - loss: 0.6492 - val_accuracy: 0.5764 - val_loss: 0.6809\n",
      "Epoch 38/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6019 - loss: 0.6479 - val_accuracy: 0.5784 - val_loss: 0.6819\n",
      "Epoch 39/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 0.6506 - val_accuracy: 0.5804 - val_loss: 0.6816\n",
      "Epoch 40/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5993 - loss: 0.6477 - val_accuracy: 0.5709 - val_loss: 0.6901\n",
      "Epoch 41/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6005 - loss: 0.6441 - val_accuracy: 0.5698 - val_loss: 0.6848\n",
      "Epoch 42/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6021 - loss: 0.6470 - val_accuracy: 0.5724 - val_loss: 0.6832\n",
      "Epoch 43/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6015 - loss: 0.6438 - val_accuracy: 0.5721 - val_loss: 0.6854\n",
      "Epoch 44/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 0.6438 - val_accuracy: 0.5778 - val_loss: 0.6848\n",
      "Epoch 45/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6095 - loss: 0.6411 - val_accuracy: 0.5709 - val_loss: 0.6879\n",
      "Epoch 46/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6182 - loss: 0.6346 - val_accuracy: 0.5744 - val_loss: 0.6876\n",
      "Epoch 47/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6122 - loss: 0.6387 - val_accuracy: 0.5769 - val_loss: 0.6863\n",
      "Epoch 48/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6207 - loss: 0.6383 - val_accuracy: 0.5752 - val_loss: 0.6864\n",
      "Epoch 49/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6170 - loss: 0.6347 - val_accuracy: 0.5635 - val_loss: 0.6936\n",
      "Epoch 50/50\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6232 - loss: 0.6348 - val_accuracy: 0.5635 - val_loss: 0.6930\n",
      "\u001b[1m383/383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Training-Validation Metrics:\n",
      "AUROC: 0.6213166224875827\n",
      "AUPRC: 0.570419133409394\n",
      "Accuracy: 0.6247958183600131\n",
      "Precision: 0.6618334892422825\n",
      "Recall: 0.47340247574439615\n",
      "F1 Score: 0.5519797152330799\n",
      "\n",
      "Validation Metrics:\n",
      "AUROC: 0.5571940023627453\n",
      "AUPRC: 0.5157796179825569\n",
      "Accuracy: 0.5635011441647597\n",
      "Precision: 0.5704162976085031\n",
      "Recall: 0.3821958456973294\n",
      "F1 Score: 0.4577114427860696\n",
      "\n",
      "Test Metrics:\n",
      "AUROC: 0.5416584672139966\n",
      "AUPRC: 0.5061673677748599\n",
      "Accuracy: 0.5317687464224384\n",
      "Precision: 0.5098591549295775\n",
      "Recall: 0.8557919621749409\n",
      "F1 Score: 0.6390114739629303\n"
     ]
    }
   ],
   "source": [
    "# CNN-LSTM MODEL \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Flatten\n",
    "\n",
    "# Load the time series data\n",
    "data = pd.read_csv('NMC.csv')\n",
    "\n",
    "# Ensure the data has the necessary columns: 'Open', 'High', 'Close', 'Volume', 'RSI', 'MA'\n",
    "assert set(['Open', 'High', 'Close', 'Volume', 'RSI', 'MA']).issubset(data.columns), \"Missing necessary columns in the data\"\n",
    "\n",
    "# Step 1: Labeling the data\n",
    "def label_data(df, interval=4):\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - interval + 1):\n",
    "        if df['Open'][i] < df['Close'][i + interval - 1]:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    labels.extend([np.nan] * (interval - 1))\n",
    "    return labels\n",
    "\n",
    "data['Label'] = label_data(data)\n",
    "\n",
    "# Drop rows with NaN labels\n",
    "data = data.dropna(subset=['Label'])\n",
    "\n",
    "# Step 2: Splitting the data\n",
    "train_size = int(len(data) * 0.7)\n",
    "val_size = int(len(data) * 0.2)\n",
    "test_size = len(data) - train_size - val_size\n",
    "\n",
    "train_data = data.iloc[:train_size]\n",
    "val_data = data.iloc[train_size:train_size + val_size]\n",
    "test_data = data.iloc[train_size + val_size:]\n",
    "\n",
    "# Step 3: Normalizing the data (without data leakage)\n",
    "scaler = StandardScaler()\n",
    "features = ['Open', 'High', 'Close', 'Volume', 'RSI', 'MA']\n",
    "\n",
    "train_data.loc[:, features] = scaler.fit_transform(train_data[features])\n",
    "val_data.loc[:, features] = scaler.transform(val_data[features])\n",
    "test_data.loc[:, features] = scaler.transform(test_data[features])\n",
    "\n",
    "# Ensure there are no NaN values\n",
    "assert not train_data[features].isnull().values.any(), \"Train data contains NaN values\"\n",
    "assert not val_data[features].isnull().values.any(), \"Validation data contains NaN values\"\n",
    "assert not test_data[features].isnull().values.any(), \"Test data contains NaN values\"\n",
    "\n",
    "# Step 4: Creating sequences\n",
    "def create_sequences(data, time_steps=4):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_steps + 1):\n",
    "        X.append(data.iloc[i:(i + time_steps), :].drop(columns=['Datetime', 'Label']).values)\n",
    "        y.append(data.iloc[i + time_steps - 1]['Label'])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_sequences(train_data)\n",
    "X_val, y_val = create_sequences(val_data)\n",
    "X_test, y_test = create_sequences(test_data)\n",
    "\n",
    "# Ensure all data is of type float\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "# Check the shapes and types of the data\n",
    "print(f\"X_train shape: {X_train.shape}, dtype: {X_train.dtype}\")\n",
    "print(f\"y_train shape: {y_train.shape}, dtype: {y_train.dtype}\")\n",
    "print(f\"X_val shape: {X_val.shape}, dtype: {X_val.dtype}\")\n",
    "print(f\"y_val shape: {y_val.shape}, dtype: {y_val.dtype}\")\n",
    "print(f\"X_test shape: {X_test.shape}, dtype: {X_test.dtype}\")\n",
    "print(f\"y_test shape: {y_test.shape}, dtype: {y_test.dtype}\")\n",
    "\n",
    "# Step 5: Building the CNN-LSTM model\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(128),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 6: Training the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Step 7: Evaluating the model\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X).round()\n",
    "    auroc = roc_auc_score(y, y_pred)\n",
    "    auprc = average_precision_score(y, y_pred)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return auroc, auprc, accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluation on training-validation set\n",
    "train_val_auroc, train_val_auprc, train_val_accuracy, train_val_precision, train_val_recall, train_val_f1 = evaluate_model(model, X_train, y_train)\n",
    "val_auroc, val_auprc, val_accuracy, val_precision, val_recall, val_f1 = evaluate_model(model, X_val, y_val)\n",
    "\n",
    "# Evaluation on test set\n",
    "test_auroc, test_auprc, test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "print(\"Training-Validation Metrics:\")\n",
    "print(f\"AUROC: {train_val_auroc}\")\n",
    "print(f\"AUPRC: {train_val_auprc}\")\n",
    "print(f\"Accuracy: {train_val_accuracy}\")\n",
    "print(f\"Precision: {train_val_precision}\")\n",
    "print(f\"Recall: {train_val_recall}\")\n",
    "print(f\"F1 Score: {train_val_f1}\")\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"AUROC: {val_auroc}\")\n",
    "print(f\"AUPRC: {val_auprc}\")\n",
    "print(f\"Accuracy: {val_accuracy}\")\n",
    "print(f\"Precision: {val_precision}\")\n",
    "print(f\"Recall: {val_recall}\")\n",
    "print(f\"F1 Score: {val_f1}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"AUROC: {test_auroc}\")\n",
    "print(f\"AUPRC: {test_auprc}\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"Precision: {test_precision}\")\n",
    "print(f\"Recall: {test_recall}\")\n",
    "print(f\"F1 Score: {test_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b1954c-cd3a-4896-a717-4e4bd33f2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT Model \n",
    "# TRAIN AND VALIDATION PROCESS\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load and preprocess the split datasets\n",
    "train_df = pd.read_csv('train_DOGE_images_with_labels.csv')\n",
    "val_df = pd.read_csv('val_DOGE_images_with_labels.csv')\n",
    "\n",
    "# Define the dataset class\n",
    "class CryptoDataset(Dataset):\n",
    "    def __init__(self, data_frame, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_frame.iloc[idx]['image_path']\n",
    "        image = Image.open(img_name).convert('RGB')  # Convert to RGB\n",
    "        label = int(self.data_frame.iloc[idx]['label'])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CryptoDataset(data_frame=train_df, transform=transform)\n",
    "val_dataset = CryptoDataset(data_frame=val_df, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)  # Ensuring no shuffle\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load pre-trained ViT model\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=2)\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training and validation loop\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    auroc = roc_auc_score(all_labels, all_probs)\n",
    "    precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n",
    "    auprc = auc(recall, precision)\n",
    "    precision_score_value = precision_score(all_labels, all_predictions)\n",
    "    recall_score_value = recall_score(all_labels, all_predictions)\n",
    "    f1_score_value = f1_score(all_labels, all_predictions)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}, Val Accuracy: {val_accuracy}, AUROC: {auroc}, AUPRC: {auprc}, Precision: {precision_score_value}, Recall: {recall_score_value}, F1 Score: {f1_score_value}')\n",
    "\n",
    "# Save the model after training\n",
    "torch.save(model.state_dict(), 'DOGE_trained_model_vit.pth')\n",
    "\n",
    "# IMPORT TEST SET\n",
    "import pandas as pd \n",
    "\n",
    "# Load the test dataset\n",
    "test_df = pd.read_csv('test_DOGE_images_with_labels.csv')\n",
    "\n",
    "print(test_df)\n",
    "\n",
    "# TEST PROCESS\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import timm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np \n",
    "\n",
    "# Define the dataset class\n",
    "class CryptoDataset(Dataset):\n",
    "    def __init__(self, data_frame, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_frame.iloc[idx]['image_path']\n",
    "        label = self.data_frame.iloc[idx]['label']  # Assuming 'label' is the column name\n",
    "        image = Image.open(img_name).convert('RGB')  # Convert to RGB\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations (same as before)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create the test dataset and DataLoader\n",
    "test_dataset = CryptoDataset(data_frame=test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load the pre-trained model (same architecture as before)\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=2)\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_state_dict(torch.load('DOGE_trained_model_vit.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Testing loop\n",
    "all_test_predictions = []\n",
    "all_test_labels = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_test_predictions.extend(predicted.cpu().numpy())\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert predictions and labels to numpy arrays\n",
    "all_test_predictions = np.array(all_test_predictions)\n",
    "all_test_labels = np.array(all_test_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_test_labels, all_test_predictions)\n",
    "precision = precision_score(all_test_labels, all_test_predictions, average='weighted')\n",
    "recall = recall_score(all_test_labels, all_test_predictions, average='weighted')\n",
    "f1 = f1_score(all_test_labels, all_test_predictions, average='weighted')\n",
    "auroc = roc_auc_score(all_test_labels, all_test_predictions, average='weighted', multi_class='ovr')\n",
    "auprc = average_precision_score(all_test_labels, all_test_predictions, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'AUROC: {auroc}')\n",
    "print(f'AUPRC: {auprc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03602e9-65d5-4761-b3c9-5c60c0085945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeiT Model \n",
    "\n",
    "# TRAIN AND VALIDATION PROCESS\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load and preprocess the split datasets\n",
    "train_df = pd.read_csv('train_DOGE_images_with_labels.csv')\n",
    "val_df = pd.read_csv('val_DOGE_images_with_labels.csv')\n",
    "\n",
    "# Define the dataset class\n",
    "class CryptoDataset(Dataset):\n",
    "    def __init__(self, data_frame, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_frame.iloc[idx]['image_path']\n",
    "        image = Image.open(img_name).convert('RGB')  # Convert to RGB\n",
    "        label = int(self.data_frame.iloc[idx]['label'])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CryptoDataset(data_frame=train_df, transform=transform)\n",
    "val_dataset = CryptoDataset(data_frame=val_df, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)  # Ensuring no shuffle\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load pre-trained DeiT model\n",
    "model = timm.create_model('deit_base_patch16_224', pretrained=True, num_classes=2)\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training and validation loop\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    auroc = roc_auc_score(all_labels, all_probs)\n",
    "    precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n",
    "    auprc = auc(recall, precision)\n",
    "    precision_score_value = precision_score(all_labels, all_predictions)\n",
    "    recall_score_value = recall_score(all_labels, all_predictions)\n",
    "    f1_score_value = f1_score(all_labels, all_predictions)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}, Val Accuracy: {val_accuracy}, AUROC: {auroc}, AUPRC: {auprc}, Precision: {precision_score_value}, Recall: {recall_score_value}, F1 Score: {f1_score_value}')\n",
    "\n",
    "# Save the model after training\n",
    "torch.save(model.state_dict(), 'DOGE_trained_model_deit.pth')\n",
    "\n",
    "# IMPORT TEST SET\n",
    "import pandas as pd \n",
    "\n",
    "# Load the test dataset\n",
    "test_df = pd.read_csv('test_DOGE_images_with_labels.csv')\n",
    "\n",
    "print(test_df)\n",
    "\n",
    "# TEST PROCESS\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import timm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np \n",
    "\n",
    "# Define the dataset class\n",
    "class CryptoDataset(Dataset):\n",
    "    def __init__(self, data_frame, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_frame.iloc[idx]['image_path']\n",
    "        label = self.data_frame.iloc[idx]['label']  # Assuming 'label' is the column name\n",
    "        image = Image.open(img_name).convert('RGB')  # Convert to RGB\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations (same as before)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create the test dataset and DataLoader\n",
    "test_dataset = CryptoDataset(data_frame=test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load the pre-trained model (same architecture as before)\n",
    "model = timm.create_model('deit_base_patch16_224', pretrained=True, num_classes=2)\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_state_dict(torch.load('DOGE_trained_model_deit.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Testing loop\n",
    "all_test_predictions = []\n",
    "all_test_labels = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_test_predictions.extend(predicted.cpu().numpy())\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert predictions and labels to numpy arrays\n",
    "all_test_predictions = np.array(all_test_predictions)\n",
    "all_test_labels = np.array(all_test_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_test_labels, all_test_predictions)\n",
    "precision = precision_score(all_test_labels, all_test_predictions, average='weighted')\n",
    "recall = recall_score(all_test_labels, all_test_predictions, average='weighted')\n",
    "f1 = f1_score(all_test_labels, all_test_predictions, average='weighted')\n",
    "auroc = roc_auc_score(all_test_labels, all_test_predictions, average='weighted', multi_class='ovr')\n",
    "auprc = average_precision_score(all_test_labels, all_test_predictions, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'AUROC: {auroc}')\n",
    "print(f'AUPRC: {auprc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94326c-87c4-48ed-953c-698bd1657d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 Model \n",
    "\n",
    "# TRAIN AND VALIDATION PROCESS\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load and preprocess the split datasets\n",
    "train_df = pd.read_csv('train_DOGE_images_with_labels.csv')\n",
    "val_df = pd.read_csv('val_DOGE_images_with_labels.csv')\n",
    "\n",
    "# Define the dataset class\n",
    "class CryptoDataset(Dataset):\n",
    "    def __init__(self, data_frame, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_frame.iloc[idx]['image_path']\n",
    "        image = Image.open(img_name).convert('RGB')  # Convert to RGB\n",
    "        label = int(self.data_frame.iloc[idx]['label'])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CryptoDataset(data_frame=train_df, transform=transform)\n",
    "val_dataset = CryptoDataset(data_frame=val_df, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)  # Ensuring no shuffle\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load pre-trained ResNet-50 model\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=2)\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training and validation loop\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    auroc = roc_auc_score(all_labels, all_probs)\n",
    "    precision, recall, _ = precision_recall_curve(all_labels, all_probs)\n",
    "    auprc = auc(recall, precision)\n",
    "    precision_score_value = precision_score(all_labels, all_predictions)\n",
    "    recall_score_value = recall_score(all_labels, all_predictions)\n",
    "    f1_score_value = f1_score(all_labels, all_predictions)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}, Val Accuracy: {val_accuracy}, AUROC: {auroc}, AUPRC: {auprc}, Precision: {precision_score_value}, Recall: {recall_score_value}, F1 Score: {f1_score_value}')\n",
    "\n",
    "# Save the model after training\n",
    "torch.save(model.state_dict(), 'DOGE_trained_model_resnet50.pth')\n",
    "\n",
    "# IMPORT TEST SET\n",
    "import pandas as pd \n",
    "\n",
    "# Load the test dataset\n",
    "test_df = pd.read_csv('test_DOGE_images_with_labels.csv')\n",
    "\n",
    "print(test_df)\n",
    "\n",
    "# TEST PROCESS\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import timm\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np \n",
    "\n",
    "# Define the dataset class\n",
    "class CryptoDataset(Dataset):\n",
    "    def __init__(self, data_frame, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_frame.iloc[idx]['image_path']\n",
    "        label = self.data_frame.iloc[idx]['label']  # Assuming 'label' is the column name\n",
    "        image = Image.open(img_name).convert('RGB')  # Convert to RGB\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations (same as before)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create the test dataset and DataLoader\n",
    "test_dataset = CryptoDataset(data_frame=test_df, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load the pre-trained model (same architecture as before)\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=2)\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_state_dict(torch.load('DOGE_trained_model_resnet50.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Testing loop\n",
    "all_test_predictions = []\n",
    "all_test_labels = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_test_predictions.extend(predicted.cpu().numpy())\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert predictions and labels to numpy arrays\n",
    "all_test_predictions = np.array(all_test_predictions)\n",
    "all_test_labels = np.array(all_test_labels)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_test_labels, all_test_predictions)\n",
    "precision = precision_score(all_test_labels, all_test_predictions, average='weighted')\n",
    "recall = recall_score(all_test_labels, all_test_predictions, average='weighted')\n",
    "f1 = f1_score(all_test_labels, all_test_predictions, average='weighted')\n",
    "auroc = roc_auc_score(all_test_labels, all_test_predictions, average='weighted', multi_class='ovr')\n",
    "auprc = average_precision_score(all_test_labels, all_test_predictions, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'AUROC: {auroc}')\n",
    "print(f'AUPRC: {auprc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
